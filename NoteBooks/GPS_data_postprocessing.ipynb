{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuClass":"premium","authorship_tag":"ABX9TyOGcx2KAdJMf/GGQNwC5FB4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Eg9DRRfBR0AG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687459029429,"user_tz":-120,"elapsed":30197,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}},"outputId":"ad28a159-3873-4c17-d88d-21bc3e694384"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","import csv\n","import numpy as np\n","import pandas as pd\n","import sys\n","from datetime import datetime"],"metadata":{"id":"Hmyv3qvnR2uu","executionInfo":{"status":"ok","timestamp":1687459029815,"user_tz":-120,"elapsed":389,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Data Path\n","root_dir = \"gdrive/My Drive/Master_Thesis/\"\n","\n","Base_dir = os.path.join(root_dir, 'data/Custom/CONAN_test.csv')\n","EDOS_dir = os.path.join(root_dir, 'data/Custom/EDOS_sexist.csv')\n","test_dir = os.path.join(root_dir, 'data/Custom/T8-S10.csv')\n","\n","data_dir = os.path.join(root_dir, 'predictions/GPS/')\n","save_dir = os.path.join(root_dir, 'predictions/')"],"metadata":{"id":"Btr6G1LaR4Nd","executionInfo":{"status":"ok","timestamp":1687459029815,"user_tz":-120,"elapsed":3,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def get_datetime(format):\n","    # datetime object containing current date and time\n","    now = datetime.now()\n","    # dd/mm/YY H:M:S\n","    dt = now.strftime(format)\n","    return dt"],"metadata":{"id":"xG2Hrmp7L3-F","executionInfo":{"status":"ok","timestamp":1687459029816,"user_tz":-120,"elapsed":4,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Read text file\n","filenames = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n","for filename in filenames:\n","  # Get method name\n","  x = filename.split('_')\n","\n","  # Open the original testset\n","  if x[0] == \"EDOS\":\n","    df = pd.read_csv(EDOS_dir)\n","    task = \"Sexism\"\n","    df = df.rename(columns={\"text\": \"Hate_Speech\"})\n","  elif x[0] == \"test\":\n","    df = pd.read_csv(test_dir)\n","    task = \"Small\"\n","  elif x[0] == \"CONAN\":\n","    df = pd.read_csv(Base_dir)\n","    task = \"Base\"\n","  else:\n","    print(\"No corresponding original testset is found, check the filename.\")\n","\n","  # Make a copy of dataframe\n","  df_ = df.copy()\n","\n","  x = x[0] + '_' + x[1] + '_'\n","  Method = os.path.splitext(filename.replace(x, ''))[0]\n","\n","  # Open file\n","  with open(data_dir + filename, 'r') as f:\n","\n","    # Read predictions\n","    predictions = []\n","    for text in f:\n","      predictions.append(text)\n","    #print(len(predictions))\n","    df_[\"Prediction\"] = predictions\n","    df_.to_csv(save_dir + 'GPS_' + Method + '_' + task + '_' + get_datetime(\"%d,%m,%Y--%H,%M\") + \".csv\")"],"metadata":{"id":"g-ZgMvg3SHLh","executionInfo":{"status":"ok","timestamp":1687459031628,"user_tz":-120,"elapsed":1815,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":5,"outputs":[]}]}