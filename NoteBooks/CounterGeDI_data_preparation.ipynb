{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPavvQl+xFn9E0bzpbYBh8f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Eg9DRRfBR0AG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683671573528,"user_tz":-120,"elapsed":17542,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}},"outputId":"b0432dcf-e125-479b-bcad-81068e1c510d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","import csv\n","import numpy as np\n","import pandas as pd\n","import sys\n","import tqdm"],"metadata":{"id":"Hmyv3qvnR2uu","executionInfo":{"status":"ok","timestamp":1683671575671,"user_tz":-120,"elapsed":1346,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pickle import NONE\n","from sklearn.model_selection import train_test_split\n","\n","# Data Path\n","root_dir = \"gdrive/My Drive/CounterGEDI/\"\n","GeDI_dir = os.path.join(root_dir, 'Datasets/Original/')\n","\n","\n","def politeness_set():\n","  Polite_ = os.path.join(GeDI_dir, 'politeness.tsv')\n","  save_dir = os.path.join(root_dir, 'Datasets/Politeness/')\n","\n","  df_polite = pd.read_table(Polite_,sep='\\t')\n","  \n","  tuple_head=[]\n","  for index,row in df_polite[df_polite['split']=='train'].iterrows():\n","    tuple_temp=[row['txt']]\n","    if(row['style']=='P_9'):\n","      tuple_temp.append('polite')\n","    else:\n","      tuple_temp.append('non_polite')\n","    tuple_head.append(tuple_temp)\n","  df_polite_train=pd.DataFrame(tuple_head,columns=['text','labels'])\n","\n","  tuple_head=[]\n","  for index,row in df_polite[df_polite['split']=='val'].iterrows():\n","    tuple_temp=[row['txt']]\n","    if(row['style']=='P_9'):\n","      tuple_temp.append('polite')\n","    else:\n","      tuple_temp.append('non_polite')\n","    tuple_head.append(tuple_temp)\n","  df_polite_val=pd.DataFrame(tuple_head,columns=['text','labels'])\n","  \n","  tuple_head=[]\n","  for index,row in df_polite[df_polite['split']=='test'].iterrows():\n","    tuple_temp=[row['txt']]\n","    if(row['style']=='P_9'):\n","      tuple_temp.append('polite')\n","    else:\n","      tuple_temp.append('non_polite')\n","    tuple_head.append(tuple_temp)\n","  df_polite_test=pd.DataFrame(tuple_head,columns=['text','labels'])\n","  \n","  os.makedirs(save_dir, exist_ok=True)\n","  save_data(save_dir, df_polite_train, df_polite_val, df_polite_test)\n","\n","def detox_set():\n","  Detox_ = os.path.join(GeDI_dir, 'detox/train.csv')\n","  Detox_test = os.path.join(GeDI_dir, 'detox/test.csv')\n","  Detox_testlabel = os.path.join(GeDI_dir, 'detox/test_labels.csv')\n","  save_dir = os.path.join(root_dir, 'Datasets/Toxicity/')\n","\n","  # read df\n","  df = pd.read_csv(Detox_)\n","  test = pd.read_csv(Detox_test)\n","  labels = pd.read_csv(Detox_testlabel)\n","\n","  # merge test set with test labels\n","  df_test = test.merge(labels, left_on='id', right_on='id')\n","\n","  def format(df):\n","    # As the author mentioned, we seperate normal text and toxic text\n","    tuple_head=[]\n","    for index,row in df.iterrows():\n","      tuple_temp=[row['id'], row['comment_text']]\n","      flag=0\n","      for ele in list(df.columns[2:]):\n","        if(row[ele]==1):\n","          tuple_temp.append('toxic')\n","          flag=1\n","          break\n","      if(flag==0):\n","        tuple_temp.append('non_toxic')\n","      tuple_head.append(tuple_temp)\n","    return pd.DataFrame(tuple_head,columns=['id','text','labels'])\n","\n","  df = format(df)\n","  test = format(df_test)\n","  \n","  # Split dataset (We stratified-split the released training dataset randomly into 90% training and 10% validation sets)\n","  train, val = train_test_split(df, stratify=df['labels'], test_size=0.1)\n","\n","  os.makedirs(save_dir, exist_ok=True)\n","  save_data(save_dir, train, val, test)\n","\n","def emo_set():\n","  Emo_ = os.path.join(GeDI_dir, 'emotion.pkl')\n","  df = pd.read_pickle(Emo_)\n","\n","  # drop samples with love OR surprise as stated in original paper\n","  df = df[(df['emotions'] == 'sadness') | (df['emotions'] == 'joy') | (df['emotions'] == 'anger') | (df['emotions'] == 'fear')]\n","\n","  # rename the emotion as labels\n","  df = df.rename(columns={'emotions': 'labels'})\n","  \n","  # Split dataset (We stratified-split each dataset randomly into training, validation, andtest set with 80%fortraining, and 10%forbothvalidation and testing.)\n","  train, val_test = train_test_split(df, stratify=df['labels'], test_size=0.2)\n","  val, test = train_test_split(val_test, stratify=val_test['labels'], test_size=0.5)\n","  \n","  save_dir = os.path.join(root_dir, 'Datasets/Emotion/')\n","\n","  os.makedirs(save_dir, exist_ok=True)\n","  save_data(save_dir, train, val, test)\n","  \n","  emotions = df[\"labels\"].unique()\n","  for emo in emotions:\n","    # As the author mentioned, we generate four different datasets with each attribute considered as positive and the others negative\n","    train['labels'] = train['labels'].apply(lambda x: emo if x == emo else 'other')\n","    val['labels'] = val['labels'].apply(lambda x: emo if x == emo else 'other')\n","    test['labels'] = test['labels'].apply(lambda x: emo if x == emo else 'other')\n","    save_dir = os.path.join(root_dir, 'Datasets/Emotion_' + emo + '/')\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","    save_data(save_dir, train, val, test)\n","\n","\n","def save_data(save_dir, train, val, test=None):\n","  train_ = os.path.join(save_dir, 'Train.csv')\n","  val_ = os.path.join(save_dir, 'Val.csv')\n","  train.to_csv(train_) \n","  val.to_csv(val_) \n","  if test is not None:\n","    test_ = os.path.join(save_dir, 'Test.csv') \n","    test.to_csv(test_) \n","\n"],"metadata":{"id":"UQ6lu_J7K7qk","executionInfo":{"status":"ok","timestamp":1683671576044,"user_tz":-120,"elapsed":377,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["politeness_set()\n","# detox_set()\n","# emo_set()"],"metadata":{"id":"li1HX_HiNP3p","executionInfo":{"status":"ok","timestamp":1683671674481,"user_tz":-120,"elapsed":92627,"user":{"displayName":"Chang YenYu","userId":"13353243669334155647"}}},"execution_count":5,"outputs":[]}]}